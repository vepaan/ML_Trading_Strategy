{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n"
     ]
    }
   ],
   "source": [
    "#Downloading and formatting the dataset\n",
    "\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-')\n",
    "symbols_list = sp500['Symbol'].unique().tolist()\n",
    "\n",
    "end_date = dt.datetime.now()\n",
    "start_date = pd.to_datetime(end_date) - pd.DateOffset(365*8)\n",
    "\n",
    "df = yf.download(tickers = symbols_list, start = start_date, end = end_date)\n",
    "df = df.stack()\n",
    "df.index.names = ['date', 'ticker']\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the technical indicators\n",
    "\n",
    "df['garman_klass_vol'] = ((np.log(df['high']) - np.log(df['low'])) ** 2) / 2 - (2 * np.log(2) - 1) * ((np.log(df['adj close']) - np.log(df['open'])) ** 2)\n",
    "df['rsi'] = df.groupby(level = 1)['adj close'].transform(lambda x: pandas_ta.rsi(close = x, length = 20))\n",
    "\n",
    "df['bb_low'] = df.groupby(level = 1)['adj close'].transform(lambda x: pandas_ta.bbands(close = np.log1p(x), length = 20).iloc[:,0])\n",
    "df['bb_mid'] = df.groupby(level = 1)['adj close'].transform(lambda x: pandas_ta.bbands(close = np.log1p(x), length = 20).iloc[:,1]) \n",
    "df['bb_high'] = df.groupby(level = 1)['adj close'].transform(lambda x: pandas_ta.bbands(close = np.log1p(x), length = 20).iloc[:,2])\n",
    "\n",
    "def compute_atr(stock_data):\n",
    "    atr = pandas_ta.atr(high = stock_data['high'],\n",
    "                        low = stock_data['low'],\n",
    "                        close = stock_data['close'],\n",
    "                        length = 14)\n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "df['atr'] = df.groupby(level = 1, group_keys = False).apply(compute_atr)\n",
    "\n",
    "def compute_macd(close):\n",
    "    macd = pandas_ta.macd(close=close, length=20)\n",
    "    if macd is not None:\n",
    "        return macd.iloc[:, 0].sub(macd.iloc[:, 0].mean()).div(macd.iloc[:, 0].std())\n",
    "    else:\n",
    "        return pd.Series([np.nan] * len(close), index=close.index)\n",
    "\n",
    "df['macd'] = df.groupby(level = 1, group_keys = False)['adj close'].apply(compute_macd)\n",
    "\n",
    "df['dollar_volume'] = (df['adj close'] * df['volume'])/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate to monthly level and filter top 150 most liquid stocks for each month\n",
    "'''This is done to reduce training time for the ML model and experiment with strats'''\n",
    "#This computes the average monthly dollar volume to give a sense of liquidity\n",
    "\n",
    "last_cols = [c for c in df.columns.unique(0) if c not in ['dollar_volume', 'volume',\n",
    "                                                          'open','high','low','close']]\n",
    "\n",
    "data = pd.concat([df.unstack('ticker')['dollar_volume'].resample('M').mean().stack().to_frame('dollar_volume'),\n",
    "          df.unstack()[last_cols].resample('M').last().stack('ticker')], axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the 5 year rolling average rolling average for each stock\n",
    "#and use this value to filter out top 150 most liquid stocks for each month\n",
    "\n",
    "data['dollar_volume'] = (data.loc[:, 'dollar_volume'].unstack('ticker').rolling(5*12, min_periods=12).mean().stack())\n",
    "\n",
    "data['dollar_vol_rank'] = data.groupby('date')['dollar_volume'].rank(ascending = False)\n",
    "\n",
    "#We are finding the 150 most liquid stocks then dropping the columns that we dont need\n",
    "data = data[data['dollar_vol_rank']<150].drop(['dollar_volume', 'dollar_vol_rank'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Removing the timezones from the dataframe data as they are not necessary'''\n",
    "#Remove the time zone from the 'date' index of data\n",
    "data.index = data.index.set_levels([data.index.levels[0].tz_localize(None), data.index.levels[1]])\n",
    "\n",
    "#Convert the 'date' index to only the date part (remove time part)\n",
    "data.index = data.index.set_levels([data.index.levels[0].date, data.index.levels[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating monthly returns for different time horizons as features\n",
    "'''To capture time series dynamics that reflect, for instance, momentum patterns, we\n",
    "compute historical returns using the method .pct_change(lag), that is, returns over\n",
    "various monthly periods as identified by lags'''\n",
    "\n",
    "def calculate_returns(df):\n",
    "\n",
    "    outlier_cutoff = 0.005 #only the 99.005 percentile is considered and values above this percentile are assigned the same value as the cutoff\n",
    "    lags = [1, 2, 3, 6, 9, 12]\n",
    "\n",
    "    for lag in lags:\n",
    "        df[f'return_{lag}m'] = (df['adj close']\n",
    "                            .pct_change(lag)\n",
    "                            .pipe(lambda x: x.clip(lower = x.quantile(outlier_cutoff),\n",
    "                                                    upper = x.quantile(1 - outlier_cutoff)))\n",
    "                                .add(1)\n",
    "                                .pow(1/lag)\n",
    "                                .sub(1))\n",
    "    return df\n",
    "    \n",
    "data = data.groupby(level = 1, group_keys = False).apply(calculate_returns).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Download FAMA-FRENCH factors and calculate rolling factor betas'''\n",
    "#we are introducing the FAMA french data to estimate the exposure of assets to\n",
    "#common risk factors with linear regression.\n",
    "#five factors are market risk size, value, operating probability and investment\n",
    "#these have been shown to empirically assess asset returns\n",
    "#we can access historical returns using pandas-datareader and estimate historial \n",
    "#exposures using Rollingols model\n",
    "\n",
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3',\n",
    "               'famafrench',\n",
    "               start = '2010')[0].drop('RF', axis = 1)\n",
    "\n",
    "factor_data.index = factor_data.index.to_timestamp() #but this returns beginning of month data, which we have to fix to end of month\n",
    "\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "\n",
    "factor_data.index.name = 'date'\n",
    "#now we just combine this with the 1 month return from previous code\n",
    "\n",
    "# '''We are adding timezones to factordata date as data has timezones'''\n",
    "# #Check if 'factor_data' is timezone-aware\n",
    "# if factor_data.index.tz is None:\n",
    "#     # If it's not timezone-aware, localize it to UTC (or any timezone you prefer)\n",
    "#     factor_data.index = factor_data.index.tz_localize('UTC')\n",
    "# else:\n",
    "#     # If it's already timezone-aware, ensure it's in the same timezone (UTC)\n",
    "#     factor_data.index = factor_data.index.tz_convert('UTC')\n",
    "# '''end of bug fix'''\n",
    "\n",
    "factor_data = factor_data.join(data['return_1m']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Filter out stocks with less than 10 months of data'''\n",
    "#we do this because we are going to use rolling window for the regression of 24mnths\n",
    "#stocks without enough data can break our functions\n",
    "\n",
    "observations = factor_data.groupby(level = 1).size()\n",
    "valid_stocks = observations[observations >= 10] #more than 10 months data\n",
    "\n",
    "factor_data = factor_data[factor_data.index.get_level_values('ticker').isin(valid_stocks.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculating the rolling factor betas'''\n",
    "\n",
    "betas = (factor_data.groupby(level = 1,\n",
    "                    group_keys = False)\n",
    "        .apply(lambda x: RollingOLS(endog = x['return_1m'],\n",
    "                                    exog = sm.add_constant(x.drop('return_1m', axis = 1)),\n",
    "                                    window = min(24, x.shape[0]), #if less than 24 months data, still calculate ols\n",
    "                                    min_nobs = len(x.columns)+1)\n",
    "        .fit(params_only = True)\n",
    "        .params\n",
    "        .drop('const', axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Joining the betas to the features as well'''\n",
    "#however we cannot blindly join betas to our dataset\n",
    "#this is because we use the factor at the beginning of the month and return at the end of the month to compute betas.\n",
    "#so at the end of the month, well be able to run the regression and have the betas but we will have them in the next month.\n",
    "#so the betas of oct 31 will be known in nov 1\n",
    "#so we shift the betas one month ahead before joining\n",
    "#doing betas.shift() will simply shift betas forward by ticker, so XOM will get WMT's beta\n",
    "\n",
    "data = data.join( betas.groupby('ticker').shift() )\n",
    "\n",
    "#removing the NaN values in the FAMA-French columns\n",
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "\n",
    "data.loc[:, factors] = data.groupby('ticker', group_keys = False)[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "data = data.dropna()\n",
    "data = data.drop('adj close', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we will start with the ML model as the data is complete'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we will start with the ML model as the data is complete'''\n",
    "#We have the top 150 most liquid stocks at the end of each month.\n",
    "#Our job is to build portfolios at the EOM and evaluate which stocks to put in.\n",
    "\n",
    "'''We'll use a K-means clustering alg to group similar assets based on their features'''\n",
    "#Split the stocks into four diff groups (optimal number of clusters as said by a quant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
